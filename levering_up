marc andreessen said that software is eating the world, and since writing software happens in the world, it would be surprising if software wasn't eating its own creation.

I thought this wasn't the case for the longest time, because I misunderstood exactly what the "eating" in "eating the world" means.  I thought something being eaten meant it vanished, the way classified sections of newspapers vanished.  There seems to be more and more software development happening, so perhaps the process of software development couldn't be eaten, or it would be eaten last, or...?  Most confusing.

But while superficially true, saying that classifieds have vanished isn't the most useful way to describe what happened.  The behavior that classified sections enabled still exists-it's just that most of it moved from newspapers to craigslist, ebay, etc..  I think this is how it generally works - physical things being eaten become mostly software (the way cameras, GPS devices, music players, etc., have been mostly subsumed by software in phones), while activities being eaten go from being mediated by humans to being mediated by machines (the way taxi dispatch by human operators moved to software written by uber, lyft, et al.).  Seen this way, software has been eaten to a great extent-we don't write code in hex, assembler or even C all that much now, but rather use higher level languages that are compiled or interpreted.  There are also specialized compilers that automate the writing of especially tedious code: I've seen thousands of lines of code generated in seconds by each of thrift, rails, and custom code generators.  Likewise, we can use code written by others, whether it is in the form of frameworks, libraries or services to do much of what we would otherwise write on our own.

Even if you look just at writing